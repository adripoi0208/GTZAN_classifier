{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b2adfb6",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f25fe527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import audioread\n",
    "import ffmpeg\n",
    "\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "import keras as k\n",
    "from keras.models import Sequential\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e20e668a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/features_3_sec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "966d9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels='filename', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd8bc543",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = df.iloc[:, -1]\n",
    "convertor = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a098afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = convertor.fit_transform(class_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68419028",
   "metadata": {},
   "source": [
    "### 2. Train/Test Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6eeab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = StandardScaler()\n",
    "X = fit.fit_transform(np.array(df.iloc[:, :-1], dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8057f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6692, 58)\n",
      "(6692,)\n",
      "(3297, 58)\n",
      "(3297,)\n"
     ]
    }
   ],
   "source": [
    "#Model 1 splitting\n",
    "X_old = X[1:9990]\n",
    "y_old = y[1:9990] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_old, y_old, test_size=0.33)\n",
    "\n",
    "print(\"There are \",X_train.shape[0],\" samples in the training set\")\n",
    "print(\"There are \",X_test.shape[0],\" samples in the testing set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b64821e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9989, 58)\n",
      "(9989,)\n",
      "(998, 58)\n",
      "(998,)\n"
     ]
    }
   ],
   "source": [
    "#Model 2 spliting\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train_2, y_train_2 = shuffle(X[1:9990], y[1:9990])\n",
    "X_test_2, y_test_2 = shuffle(X[9991:10989], y[9991:10989])\n",
    "\n",
    "print(\"There are \",X_train_2.shape[0],\" samples in the training set\")\n",
    "print(\"There are \",X_test_2.shape[0],\" samples in the testing set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e4ed0ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7370, 58)\n",
      "(7370,)\n",
      "(3631, 58)\n",
      "(3631,)\n"
     ]
    }
   ],
   "source": [
    "#Model 3 splitting\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "print(\"There are \",X_train_3.shape[0],\" samples in the training set\")\n",
    "print(\"There are \",X_test_3.shape[0],\" samples in the testing set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb23c4",
   "metadata": {},
   "source": [
    "## 3. Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7418987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, optimizer):\n",
    "    batch_size = 128\n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics='accuracy'\n",
    "    )\n",
    "    return model.fit(X_train_3, y_train_3, validation_data=(X_test_3, y_test_3), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6fb5f2e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 512)               30208     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203,338\n",
      "Trainable params: 203,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/600\n",
      "58/58 [==============================] - 2s 15ms/step - loss: 1.6704 - accuracy: 0.4047 - val_loss: 1.1893 - val_accuracy: 0.5943\n",
      "Epoch 2/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 1.1925 - accuracy: 0.5843 - val_loss: 0.9408 - val_accuracy: 0.6742\n",
      "Epoch 3/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 1.0001 - accuracy: 0.6558 - val_loss: 0.8250 - val_accuracy: 0.7205\n",
      "Epoch 4/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.8972 - accuracy: 0.6909 - val_loss: 0.7318 - val_accuracy: 0.7502\n",
      "Epoch 5/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.8009 - accuracy: 0.7316 - val_loss: 0.6798 - val_accuracy: 0.7733\n",
      "Epoch 6/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.7084 - accuracy: 0.7593 - val_loss: 0.6477 - val_accuracy: 0.7830\n",
      "Epoch 7/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.6544 - accuracy: 0.7750 - val_loss: 0.5980 - val_accuracy: 0.7995\n",
      "Epoch 8/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.5963 - accuracy: 0.8020 - val_loss: 0.5716 - val_accuracy: 0.8086\n",
      "Epoch 9/600\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.5489 - accuracy: 0.8133 - val_loss: 0.5303 - val_accuracy: 0.8224\n",
      "Epoch 10/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.4988 - accuracy: 0.8261 - val_loss: 0.5342 - val_accuracy: 0.8240\n",
      "Epoch 11/600\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.4636 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.8392\n",
      "Epoch 12/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.4072 - accuracy: 0.8674 - val_loss: 0.4717 - val_accuracy: 0.8458\n",
      "Epoch 13/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.3911 - accuracy: 0.8699 - val_loss: 0.4630 - val_accuracy: 0.8471\n",
      "Epoch 14/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.3582 - accuracy: 0.8798 - val_loss: 0.4797 - val_accuracy: 0.8516\n",
      "Epoch 15/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.3362 - accuracy: 0.8908 - val_loss: 0.4326 - val_accuracy: 0.8623\n",
      "Epoch 16/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.3182 - accuracy: 0.8932 - val_loss: 0.4591 - val_accuracy: 0.8529\n",
      "Epoch 17/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.2789 - accuracy: 0.9057 - val_loss: 0.4392 - val_accuracy: 0.8637\n",
      "Epoch 18/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.2601 - accuracy: 0.9125 - val_loss: 0.4226 - val_accuracy: 0.8659\n",
      "Epoch 19/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.2458 - accuracy: 0.9174 - val_loss: 0.4096 - val_accuracy: 0.8689\n",
      "Epoch 20/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.2442 - accuracy: 0.9195 - val_loss: 0.4362 - val_accuracy: 0.8670\n",
      "Epoch 21/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.2243 - accuracy: 0.9269 - val_loss: 0.4175 - val_accuracy: 0.8736\n",
      "Epoch 22/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.2104 - accuracy: 0.9299 - val_loss: 0.4102 - val_accuracy: 0.8780\n",
      "Epoch 23/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.1998 - accuracy: 0.9366 - val_loss: 0.3950 - val_accuracy: 0.8813\n",
      "Epoch 24/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.1771 - accuracy: 0.9411 - val_loss: 0.3945 - val_accuracy: 0.8841\n",
      "Epoch 25/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.1684 - accuracy: 0.9446 - val_loss: 0.3956 - val_accuracy: 0.8896\n",
      "Epoch 26/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.1618 - accuracy: 0.9483 - val_loss: 0.3933 - val_accuracy: 0.8824\n",
      "Epoch 27/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.1654 - accuracy: 0.9461 - val_loss: 0.3958 - val_accuracy: 0.8871\n",
      "Epoch 28/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.1390 - accuracy: 0.9531 - val_loss: 0.4157 - val_accuracy: 0.8807\n",
      "Epoch 29/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.1646 - accuracy: 0.9456 - val_loss: 0.4347 - val_accuracy: 0.8802\n",
      "Epoch 30/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.1471 - accuracy: 0.9520 - val_loss: 0.4103 - val_accuracy: 0.8879\n",
      "Epoch 31/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.1237 - accuracy: 0.9619 - val_loss: 0.3939 - val_accuracy: 0.8887\n",
      "Epoch 32/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.1267 - accuracy: 0.9575 - val_loss: 0.4048 - val_accuracy: 0.8945\n",
      "Epoch 33/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.1150 - accuracy: 0.9609 - val_loss: 0.4410 - val_accuracy: 0.8841\n",
      "Epoch 34/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.1182 - accuracy: 0.9604 - val_loss: 0.3909 - val_accuracy: 0.8937\n",
      "Epoch 35/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.1108 - accuracy: 0.9640 - val_loss: 0.3858 - val_accuracy: 0.8981\n",
      "Epoch 36/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.1041 - accuracy: 0.9674 - val_loss: 0.4172 - val_accuracy: 0.8912\n",
      "Epoch 37/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.1172 - accuracy: 0.9626 - val_loss: 0.4138 - val_accuracy: 0.8854\n",
      "Epoch 38/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.1130 - accuracy: 0.9632 - val_loss: 0.4054 - val_accuracy: 0.8882\n",
      "Epoch 39/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.1058 - accuracy: 0.9661 - val_loss: 0.4173 - val_accuracy: 0.8898\n",
      "Epoch 40/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.1025 - accuracy: 0.9666 - val_loss: 0.4137 - val_accuracy: 0.8940\n",
      "Epoch 41/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0962 - accuracy: 0.9696 - val_loss: 0.3946 - val_accuracy: 0.8964\n",
      "Epoch 42/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0896 - accuracy: 0.9710 - val_loss: 0.4415 - val_accuracy: 0.8915\n",
      "Epoch 43/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0929 - accuracy: 0.9693 - val_loss: 0.4258 - val_accuracy: 0.8956\n",
      "Epoch 44/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0932 - accuracy: 0.9708 - val_loss: 0.4090 - val_accuracy: 0.8923\n",
      "Epoch 45/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0949 - accuracy: 0.9668 - val_loss: 0.4040 - val_accuracy: 0.8926\n",
      "Epoch 46/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0718 - accuracy: 0.9768 - val_loss: 0.3861 - val_accuracy: 0.9022\n",
      "Epoch 47/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0804 - accuracy: 0.9741 - val_loss: 0.4257 - val_accuracy: 0.8953\n",
      "Epoch 48/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0819 - accuracy: 0.9727 - val_loss: 0.4273 - val_accuracy: 0.9000\n",
      "Epoch 49/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0723 - accuracy: 0.9760 - val_loss: 0.4015 - val_accuracy: 0.9055\n",
      "Epoch 50/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0838 - accuracy: 0.9737 - val_loss: 0.4294 - val_accuracy: 0.8937\n",
      "Epoch 51/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0920 - accuracy: 0.9701 - val_loss: 0.4132 - val_accuracy: 0.8984\n",
      "Epoch 52/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0831 - accuracy: 0.9742 - val_loss: 0.4259 - val_accuracy: 0.8973\n",
      "Epoch 53/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0627 - accuracy: 0.9799 - val_loss: 0.4352 - val_accuracy: 0.8995\n",
      "Epoch 54/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0726 - accuracy: 0.9761 - val_loss: 0.4303 - val_accuracy: 0.8981\n",
      "Epoch 55/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0774 - accuracy: 0.9737 - val_loss: 0.4402 - val_accuracy: 0.8973\n",
      "Epoch 56/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0830 - accuracy: 0.9734 - val_loss: 0.4264 - val_accuracy: 0.9000\n",
      "Epoch 57/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0618 - accuracy: 0.9790 - val_loss: 0.4340 - val_accuracy: 0.8964\n",
      "Epoch 58/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0670 - accuracy: 0.9788 - val_loss: 0.4267 - val_accuracy: 0.8995\n",
      "Epoch 59/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0647 - accuracy: 0.9809 - val_loss: 0.4261 - val_accuracy: 0.8959\n",
      "Epoch 60/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0622 - accuracy: 0.9790 - val_loss: 0.4437 - val_accuracy: 0.8956\n",
      "Epoch 61/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0724 - accuracy: 0.9787 - val_loss: 0.4158 - val_accuracy: 0.8970\n",
      "Epoch 62/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 0.9820 - val_loss: 0.4325 - val_accuracy: 0.8981\n",
      "Epoch 63/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0600 - accuracy: 0.9810 - val_loss: 0.4429 - val_accuracy: 0.8981\n",
      "Epoch 64/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0565 - accuracy: 0.9826 - val_loss: 0.4360 - val_accuracy: 0.8992\n",
      "Epoch 65/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0547 - accuracy: 0.9840 - val_loss: 0.4156 - val_accuracy: 0.9022\n",
      "Epoch 66/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0582 - accuracy: 0.9826 - val_loss: 0.4515 - val_accuracy: 0.8984\n",
      "Epoch 67/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0662 - accuracy: 0.9788 - val_loss: 0.3990 - val_accuracy: 0.9055\n",
      "Epoch 68/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0544 - accuracy: 0.9811 - val_loss: 0.4479 - val_accuracy: 0.8987\n",
      "Epoch 69/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0528 - accuracy: 0.9821 - val_loss: 0.4372 - val_accuracy: 0.8998\n",
      "Epoch 70/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0678 - accuracy: 0.9799 - val_loss: 0.4276 - val_accuracy: 0.9028\n",
      "Epoch 71/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0601 - accuracy: 0.9815 - val_loss: 0.4436 - val_accuracy: 0.9047\n",
      "Epoch 72/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0563 - accuracy: 0.9833 - val_loss: 0.4817 - val_accuracy: 0.9011\n",
      "Epoch 73/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 0.4446 - val_accuracy: 0.9017\n",
      "Epoch 74/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0533 - accuracy: 0.9847 - val_loss: 0.4490 - val_accuracy: 0.8989\n",
      "Epoch 75/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0566 - accuracy: 0.9829 - val_loss: 0.3944 - val_accuracy: 0.9061\n",
      "Epoch 76/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 0.4481 - val_accuracy: 0.9050\n",
      "Epoch 77/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0376 - accuracy: 0.9872 - val_loss: 0.4645 - val_accuracy: 0.9044\n",
      "Epoch 78/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0498 - accuracy: 0.9858 - val_loss: 0.4824 - val_accuracy: 0.8962\n",
      "Epoch 79/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0451 - accuracy: 0.9845 - val_loss: 0.4249 - val_accuracy: 0.9077\n",
      "Epoch 80/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0459 - accuracy: 0.9849 - val_loss: 0.4482 - val_accuracy: 0.8964\n",
      "Epoch 81/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0462 - accuracy: 0.9863 - val_loss: 0.4421 - val_accuracy: 0.8987\n",
      "Epoch 82/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0570 - accuracy: 0.9821 - val_loss: 0.4797 - val_accuracy: 0.8992\n",
      "Epoch 83/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0635 - accuracy: 0.9825 - val_loss: 0.4864 - val_accuracy: 0.8964\n",
      "Epoch 84/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0597 - accuracy: 0.9820 - val_loss: 0.4908 - val_accuracy: 0.8956\n",
      "Epoch 85/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0478 - accuracy: 0.9855 - val_loss: 0.4697 - val_accuracy: 0.8937\n",
      "Epoch 86/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0563 - accuracy: 0.9836 - val_loss: 0.4757 - val_accuracy: 0.8964\n",
      "Epoch 87/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0457 - accuracy: 0.9836 - val_loss: 0.4601 - val_accuracy: 0.8989\n",
      "Epoch 88/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0401 - accuracy: 0.9875 - val_loss: 0.4547 - val_accuracy: 0.9033\n",
      "Epoch 89/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0549 - accuracy: 0.9847 - val_loss: 0.4473 - val_accuracy: 0.9058\n",
      "Epoch 90/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0485 - accuracy: 0.9843 - val_loss: 0.4648 - val_accuracy: 0.9031\n",
      "Epoch 91/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0508 - accuracy: 0.9833 - val_loss: 0.4484 - val_accuracy: 0.9033\n",
      "Epoch 92/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0478 - accuracy: 0.9840 - val_loss: 0.4813 - val_accuracy: 0.9009\n",
      "Epoch 93/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.4964 - val_accuracy: 0.8992\n",
      "Epoch 94/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.4463 - val_accuracy: 0.9033\n",
      "Epoch 95/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0337 - accuracy: 0.9908 - val_loss: 0.4473 - val_accuracy: 0.9061\n",
      "Epoch 96/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0399 - accuracy: 0.9887 - val_loss: 0.4594 - val_accuracy: 0.9022\n",
      "Epoch 97/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0437 - accuracy: 0.9859 - val_loss: 0.4425 - val_accuracy: 0.9053\n",
      "Epoch 98/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0417 - accuracy: 0.9878 - val_loss: 0.4621 - val_accuracy: 0.9025\n",
      "Epoch 99/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0552 - accuracy: 0.9858 - val_loss: 0.4557 - val_accuracy: 0.9033\n",
      "Epoch 100/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0419 - accuracy: 0.9856 - val_loss: 0.4529 - val_accuracy: 0.9031\n",
      "Epoch 101/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 0.4654 - val_accuracy: 0.9028\n",
      "Epoch 102/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 0.4606 - val_accuracy: 0.9069\n",
      "Epoch 103/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0438 - accuracy: 0.9875 - val_loss: 0.4455 - val_accuracy: 0.9036\n",
      "Epoch 104/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9889 - val_loss: 0.4818 - val_accuracy: 0.9017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0365 - accuracy: 0.9890 - val_loss: 0.5073 - val_accuracy: 0.8967\n",
      "Epoch 106/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0403 - accuracy: 0.9879 - val_loss: 0.4705 - val_accuracy: 0.9022\n",
      "Epoch 107/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0519 - accuracy: 0.9859 - val_loss: 0.4581 - val_accuracy: 0.9020\n",
      "Epoch 108/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0565 - accuracy: 0.9814 - val_loss: 0.4666 - val_accuracy: 0.9028\n",
      "Epoch 109/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0480 - accuracy: 0.9845 - val_loss: 0.4395 - val_accuracy: 0.9047\n",
      "Epoch 110/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.4574 - val_accuracy: 0.9053\n",
      "Epoch 111/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 0.9889 - val_loss: 0.4426 - val_accuracy: 0.9058\n",
      "Epoch 112/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0416 - accuracy: 0.9866 - val_loss: 0.4467 - val_accuracy: 0.9058\n",
      "Epoch 113/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 0.4232 - val_accuracy: 0.9064\n",
      "Epoch 114/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0351 - accuracy: 0.9878 - val_loss: 0.4832 - val_accuracy: 0.9020\n",
      "Epoch 115/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 0.9889 - val_loss: 0.4412 - val_accuracy: 0.9121\n",
      "Epoch 116/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0364 - accuracy: 0.9890 - val_loss: 0.4788 - val_accuracy: 0.8998\n",
      "Epoch 117/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.9900 - val_loss: 0.4701 - val_accuracy: 0.9099\n",
      "Epoch 118/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0381 - accuracy: 0.9882 - val_loss: 0.4681 - val_accuracy: 0.9025\n",
      "Epoch 119/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0470 - accuracy: 0.9858 - val_loss: 0.4710 - val_accuracy: 0.9017\n",
      "Epoch 120/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0390 - accuracy: 0.9886 - val_loss: 0.4392 - val_accuracy: 0.9099\n",
      "Epoch 121/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0382 - accuracy: 0.9868 - val_loss: 0.4481 - val_accuracy: 0.9050\n",
      "Epoch 122/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.4487 - val_accuracy: 0.9075\n",
      "Epoch 123/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.4868 - val_accuracy: 0.9036\n",
      "Epoch 124/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0412 - accuracy: 0.9855 - val_loss: 0.4816 - val_accuracy: 0.9025\n",
      "Epoch 125/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.4701 - val_accuracy: 0.9050\n",
      "Epoch 126/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 0.9889 - val_loss: 0.4603 - val_accuracy: 0.9061\n",
      "Epoch 127/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.4738 - val_accuracy: 0.9020\n",
      "Epoch 128/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0297 - accuracy: 0.9894 - val_loss: 0.4829 - val_accuracy: 0.9022\n",
      "Epoch 129/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0400 - accuracy: 0.9885 - val_loss: 0.4671 - val_accuracy: 0.9006\n",
      "Epoch 130/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0398 - accuracy: 0.9879 - val_loss: 0.4395 - val_accuracy: 0.9069\n",
      "Epoch 131/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0402 - accuracy: 0.9864 - val_loss: 0.4455 - val_accuracy: 0.9053\n",
      "Epoch 132/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0363 - accuracy: 0.9890 - val_loss: 0.4456 - val_accuracy: 0.9075\n",
      "Epoch 133/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0355 - accuracy: 0.9894 - val_loss: 0.4698 - val_accuracy: 0.9053\n",
      "Epoch 134/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 0.4783 - val_accuracy: 0.9025\n",
      "Epoch 135/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0414 - accuracy: 0.9866 - val_loss: 0.4542 - val_accuracy: 0.9088\n",
      "Epoch 136/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0287 - accuracy: 0.9910 - val_loss: 0.4547 - val_accuracy: 0.9083\n",
      "Epoch 137/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0362 - accuracy: 0.9878 - val_loss: 0.4818 - val_accuracy: 0.9036\n",
      "Epoch 138/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.4890 - val_accuracy: 0.8989\n",
      "Epoch 139/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0390 - accuracy: 0.9886 - val_loss: 0.4458 - val_accuracy: 0.9077\n",
      "Epoch 140/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0389 - accuracy: 0.9883 - val_loss: 0.4420 - val_accuracy: 0.9069\n",
      "Epoch 141/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0357 - accuracy: 0.9896 - val_loss: 0.4628 - val_accuracy: 0.9006\n",
      "Epoch 142/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0423 - accuracy: 0.9887 - val_loss: 0.4595 - val_accuracy: 0.9061\n",
      "Epoch 143/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0292 - accuracy: 0.9898 - val_loss: 0.4600 - val_accuracy: 0.9066\n",
      "Epoch 144/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.4702 - val_accuracy: 0.9044\n",
      "Epoch 145/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.5135 - val_accuracy: 0.9039\n",
      "Epoch 146/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0261 - accuracy: 0.9902 - val_loss: 0.5243 - val_accuracy: 0.9088\n",
      "Epoch 147/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0295 - accuracy: 0.9901 - val_loss: 0.5096 - val_accuracy: 0.9020\n",
      "Epoch 148/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0339 - accuracy: 0.9904 - val_loss: 0.5394 - val_accuracy: 0.9022\n",
      "Epoch 149/600\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.0335 - accuracy: 0.9898 - val_loss: 0.4748 - val_accuracy: 0.9124\n",
      "Epoch 150/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.4859 - val_accuracy: 0.9088\n",
      "Epoch 151/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0480 - accuracy: 0.9853 - val_loss: 0.4348 - val_accuracy: 0.9053\n",
      "Epoch 152/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0374 - accuracy: 0.9882 - val_loss: 0.4771 - val_accuracy: 0.9066\n",
      "Epoch 153/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.4618 - val_accuracy: 0.9069\n",
      "Epoch 154/600\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.5132 - val_accuracy: 0.8998\n",
      "Epoch 155/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 0.4766 - val_accuracy: 0.9072\n",
      "Epoch 156/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.4662 - val_accuracy: 0.9086\n",
      "Epoch 157/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.4505 - val_accuracy: 0.9105\n",
      "Epoch 158/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0232 - accuracy: 0.9934 - val_loss: 0.4777 - val_accuracy: 0.9097\n",
      "Epoch 159/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0399 - accuracy: 0.9889 - val_loss: 0.5760 - val_accuracy: 0.9000\n",
      "Epoch 160/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0311 - accuracy: 0.9916 - val_loss: 0.5076 - val_accuracy: 0.9047\n",
      "Epoch 161/600\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.0251 - accuracy: 0.9931 - val_loss: 0.4989 - val_accuracy: 0.9077\n",
      "Epoch 162/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.4627 - val_accuracy: 0.9072\n",
      "Epoch 163/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0328 - accuracy: 0.9905 - val_loss: 0.4461 - val_accuracy: 0.9110\n",
      "Epoch 164/600\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.0333 - accuracy: 0.9901 - val_loss: 0.4480 - val_accuracy: 0.9050\n",
      "Epoch 165/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0244 - accuracy: 0.9912 - val_loss: 0.4856 - val_accuracy: 0.9091\n",
      "Epoch 166/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0310 - accuracy: 0.9924 - val_loss: 0.4787 - val_accuracy: 0.9135\n",
      "Epoch 167/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0299 - accuracy: 0.9909 - val_loss: 0.4818 - val_accuracy: 0.9064\n",
      "Epoch 168/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 0.5048 - val_accuracy: 0.9050\n",
      "Epoch 169/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.4792 - val_accuracy: 0.9119\n",
      "Epoch 170/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.5024 - val_accuracy: 0.9097\n",
      "Epoch 171/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.4874 - val_accuracy: 0.9149\n",
      "Epoch 172/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.5296 - val_accuracy: 0.9072\n",
      "Epoch 173/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0446 - accuracy: 0.9875 - val_loss: 0.4793 - val_accuracy: 0.9113\n",
      "Epoch 174/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0263 - accuracy: 0.9924 - val_loss: 0.4698 - val_accuracy: 0.9066\n",
      "Epoch 175/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0430 - accuracy: 0.9871 - val_loss: 0.4798 - val_accuracy: 0.9031\n",
      "Epoch 176/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.5085 - val_accuracy: 0.9039\n",
      "Epoch 177/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.5007 - val_accuracy: 0.9099\n",
      "Epoch 178/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.5008 - val_accuracy: 0.9121\n",
      "Epoch 179/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0319 - accuracy: 0.9921 - val_loss: 0.4717 - val_accuracy: 0.9113\n",
      "Epoch 180/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0293 - accuracy: 0.9925 - val_loss: 0.4999 - val_accuracy: 0.9097\n",
      "Epoch 181/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0346 - accuracy: 0.9902 - val_loss: 0.5019 - val_accuracy: 0.9077\n",
      "Epoch 182/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.4459 - val_accuracy: 0.9094\n",
      "Epoch 183/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0221 - accuracy: 0.9919 - val_loss: 0.4661 - val_accuracy: 0.9132\n",
      "Epoch 184/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.4899 - val_accuracy: 0.9124\n",
      "Epoch 185/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.5098 - val_accuracy: 0.9064\n",
      "Epoch 186/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.4928 - val_accuracy: 0.9061\n",
      "Epoch 187/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.5527 - val_accuracy: 0.9097\n",
      "Epoch 188/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0317 - accuracy: 0.9919 - val_loss: 0.5330 - val_accuracy: 0.9022\n",
      "Epoch 189/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.5253 - val_accuracy: 0.9091\n",
      "Epoch 190/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.5288 - val_accuracy: 0.9121\n",
      "Epoch 191/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.5249 - val_accuracy: 0.9116\n",
      "Epoch 192/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.5001 - val_accuracy: 0.9053\n",
      "Epoch 193/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0305 - accuracy: 0.9915 - val_loss: 0.4954 - val_accuracy: 0.9088\n",
      "Epoch 194/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0283 - accuracy: 0.9901 - val_loss: 0.5276 - val_accuracy: 0.9061\n",
      "Epoch 195/600\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.5089 - val_accuracy: 0.9091\n",
      "Epoch 196/600\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.5330 - val_accuracy: 0.9050\n",
      "Epoch 197/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9929 - val_loss: 0.5413 - val_accuracy: 0.8970\n",
      "Epoch 198/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.5094 - val_accuracy: 0.9086\n",
      "Epoch 199/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0241 - accuracy: 0.9925 - val_loss: 0.5035 - val_accuracy: 0.9075\n",
      "Epoch 200/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.5117 - val_accuracy: 0.9077\n",
      "Epoch 201/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.5333 - val_accuracy: 0.9066\n",
      "Epoch 202/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0239 - accuracy: 0.9939 - val_loss: 0.4968 - val_accuracy: 0.9058\n",
      "Epoch 203/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.5295 - val_accuracy: 0.9075\n",
      "Epoch 204/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.5278 - val_accuracy: 0.9044\n",
      "Epoch 205/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0232 - accuracy: 0.9910 - val_loss: 0.5357 - val_accuracy: 0.9069\n",
      "Epoch 206/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 0.9900 - val_loss: 0.5375 - val_accuracy: 0.9031\n",
      "Epoch 207/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.4928 - val_accuracy: 0.9097\n",
      "Epoch 208/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 0.4940 - val_accuracy: 0.9083\n",
      "Epoch 209/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 0.5537 - val_accuracy: 0.9091\n",
      "Epoch 210/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0178 - accuracy: 0.9936 - val_loss: 0.5444 - val_accuracy: 0.9075\n",
      "Epoch 211/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.5395 - val_accuracy: 0.9132\n",
      "Epoch 212/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0287 - accuracy: 0.9909 - val_loss: 0.5034 - val_accuracy: 0.9135\n",
      "Epoch 213/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.5484 - val_accuracy: 0.9080\n",
      "Epoch 214/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0272 - accuracy: 0.9934 - val_loss: 0.5132 - val_accuracy: 0.9105\n",
      "Epoch 215/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0295 - accuracy: 0.9919 - val_loss: 0.5266 - val_accuracy: 0.9042\n",
      "Epoch 216/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.5356 - val_accuracy: 0.9086\n",
      "Epoch 217/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.5209 - val_accuracy: 0.9033\n",
      "Epoch 218/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.5043 - val_accuracy: 0.9039\n",
      "Epoch 219/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.5093 - val_accuracy: 0.9066\n",
      "Epoch 220/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0222 - accuracy: 0.9920 - val_loss: 0.5071 - val_accuracy: 0.9050\n",
      "Epoch 221/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.5317 - val_accuracy: 0.9053\n",
      "Epoch 222/600\n",
      "58/58 [==============================] - 1s 16ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.5153 - val_accuracy: 0.9097\n",
      "Epoch 223/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.5059 - val_accuracy: 0.9058\n",
      "Epoch 224/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0254 - accuracy: 0.9923 - val_loss: 0.4944 - val_accuracy: 0.9097\n",
      "Epoch 225/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.5074 - val_accuracy: 0.9124\n",
      "Epoch 226/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.5212 - val_accuracy: 0.9097\n",
      "Epoch 227/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.5623 - val_accuracy: 0.9031\n",
      "Epoch 228/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0309 - accuracy: 0.9919 - val_loss: 0.5315 - val_accuracy: 0.9066\n",
      "Epoch 229/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.5226 - val_accuracy: 0.9097\n",
      "Epoch 230/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.5293 - val_accuracy: 0.9108\n",
      "Epoch 231/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.5372 - val_accuracy: 0.9069\n",
      "Epoch 232/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0253 - accuracy: 0.9923 - val_loss: 0.5211 - val_accuracy: 0.9099\n",
      "Epoch 233/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0211 - accuracy: 0.9935 - val_loss: 0.5632 - val_accuracy: 0.9055\n",
      "Epoch 234/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.5056 - val_accuracy: 0.9127\n",
      "Epoch 235/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0285 - accuracy: 0.9904 - val_loss: 0.5425 - val_accuracy: 0.9121\n",
      "Epoch 236/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 0.5336 - val_accuracy: 0.9110\n",
      "Epoch 237/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 0.5288 - val_accuracy: 0.9072\n",
      "Epoch 238/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.5269 - val_accuracy: 0.9127\n",
      "Epoch 239/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.4981 - val_accuracy: 0.9135\n",
      "Epoch 240/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0258 - accuracy: 0.9919 - val_loss: 0.5207 - val_accuracy: 0.9135\n",
      "Epoch 241/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0228 - accuracy: 0.9939 - val_loss: 0.5245 - val_accuracy: 0.9135\n",
      "Epoch 242/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.5487 - val_accuracy: 0.9116\n",
      "Epoch 243/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.5126 - val_accuracy: 0.9168\n",
      "Epoch 244/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0272 - accuracy: 0.9908 - val_loss: 0.4960 - val_accuracy: 0.9116\n",
      "Epoch 245/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.4992 - val_accuracy: 0.9108\n",
      "Epoch 246/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0252 - accuracy: 0.9939 - val_loss: 0.5142 - val_accuracy: 0.9077\n",
      "Epoch 247/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.4978 - val_accuracy: 0.9105\n",
      "Epoch 248/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0215 - accuracy: 0.9924 - val_loss: 0.5268 - val_accuracy: 0.9127\n",
      "Epoch 249/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0271 - accuracy: 0.9925 - val_loss: 0.4837 - val_accuracy: 0.9124\n",
      "Epoch 250/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0230 - accuracy: 0.9919 - val_loss: 0.5234 - val_accuracy: 0.9108\n",
      "Epoch 251/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0304 - accuracy: 0.9901 - val_loss: 0.4773 - val_accuracy: 0.9116\n",
      "Epoch 252/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.4927 - val_accuracy: 0.9110\n",
      "Epoch 253/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0203 - accuracy: 0.9947 - val_loss: 0.4974 - val_accuracy: 0.9099\n",
      "Epoch 254/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.5177 - val_accuracy: 0.9119\n",
      "Epoch 255/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.5363 - val_accuracy: 0.9066\n",
      "Epoch 256/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 0.5196 - val_accuracy: 0.9108\n",
      "Epoch 257/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.5296 - val_accuracy: 0.9086\n",
      "Epoch 258/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.4868 - val_accuracy: 0.9124\n",
      "Epoch 259/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.4890 - val_accuracy: 0.9141\n",
      "Epoch 260/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 0.5248 - val_accuracy: 0.9124\n",
      "Epoch 261/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.4815 - val_accuracy: 0.9146\n",
      "Epoch 262/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9938 - val_loss: 0.5218 - val_accuracy: 0.9088\n",
      "Epoch 263/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 0.4968 - val_accuracy: 0.9124\n",
      "Epoch 264/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.5254 - val_accuracy: 0.9086\n",
      "Epoch 265/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.4787 - val_accuracy: 0.9135\n",
      "Epoch 266/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.4880 - val_accuracy: 0.9146\n",
      "Epoch 267/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 0.4967 - val_accuracy: 0.9130\n",
      "Epoch 268/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.4797 - val_accuracy: 0.9141\n",
      "Epoch 269/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.5303 - val_accuracy: 0.9113\n",
      "Epoch 270/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9942 - val_loss: 0.5110 - val_accuracy: 0.9124\n",
      "Epoch 271/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.4908 - val_accuracy: 0.9127\n",
      "Epoch 272/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.4968 - val_accuracy: 0.9185\n",
      "Epoch 273/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.5173 - val_accuracy: 0.9152\n",
      "Epoch 274/600\n",
      "58/58 [==============================] - 1s 15ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.5407 - val_accuracy: 0.9124\n",
      "Epoch 275/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.4954 - val_accuracy: 0.9166\n",
      "Epoch 276/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.4892 - val_accuracy: 0.9135\n",
      "Epoch 277/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.4866 - val_accuracy: 0.9155\n",
      "Epoch 278/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.5201 - val_accuracy: 0.9108\n",
      "Epoch 279/600\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.5356 - val_accuracy: 0.9083\n",
      "Epoch 280/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.5211 - val_accuracy: 0.9124\n",
      "Epoch 281/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.5193 - val_accuracy: 0.9102\n",
      "Epoch 282/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.5375 - val_accuracy: 0.9108\n",
      "Epoch 283/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0320 - accuracy: 0.9897 - val_loss: 0.5013 - val_accuracy: 0.9102\n",
      "Epoch 284/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.4752 - val_accuracy: 0.9149\n",
      "Epoch 285/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0224 - accuracy: 0.9940 - val_loss: 0.5157 - val_accuracy: 0.9121\n",
      "Epoch 286/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.5296 - val_accuracy: 0.9121\n",
      "Epoch 287/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.5177 - val_accuracy: 0.9127\n",
      "Epoch 288/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.5382 - val_accuracy: 0.9094\n",
      "Epoch 289/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.5425 - val_accuracy: 0.9110\n",
      "Epoch 290/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.5422 - val_accuracy: 0.9113\n",
      "Epoch 291/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 0.5547 - val_accuracy: 0.9124\n",
      "Epoch 292/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.5242 - val_accuracy: 0.9116\n",
      "Epoch 293/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.5288 - val_accuracy: 0.9110\n",
      "Epoch 294/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0217 - accuracy: 0.9935 - val_loss: 0.5152 - val_accuracy: 0.9119\n",
      "Epoch 295/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.5371 - val_accuracy: 0.9105\n",
      "Epoch 296/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.5241 - val_accuracy: 0.9064\n",
      "Epoch 297/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.5630 - val_accuracy: 0.9025\n",
      "Epoch 298/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0247 - accuracy: 0.9923 - val_loss: 0.5344 - val_accuracy: 0.9075\n",
      "Epoch 299/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.5137 - val_accuracy: 0.9124\n",
      "Epoch 300/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.4879 - val_accuracy: 0.9182\n",
      "Epoch 301/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.5231 - val_accuracy: 0.9110\n",
      "Epoch 302/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0200 - accuracy: 0.9940 - val_loss: 0.5262 - val_accuracy: 0.9110\n",
      "Epoch 303/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.5390 - val_accuracy: 0.9119\n",
      "Epoch 304/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.5226 - val_accuracy: 0.9108\n",
      "Epoch 305/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.5651 - val_accuracy: 0.9138\n",
      "Epoch 306/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0225 - accuracy: 0.9934 - val_loss: 0.5270 - val_accuracy: 0.9135\n",
      "Epoch 307/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.5842 - val_accuracy: 0.9097\n",
      "Epoch 308/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.5520 - val_accuracy: 0.9086\n",
      "Epoch 309/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.5468 - val_accuracy: 0.9141\n",
      "Epoch 310/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.5111 - val_accuracy: 0.9163\n",
      "Epoch 311/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0180 - accuracy: 0.9948 - val_loss: 0.5098 - val_accuracy: 0.9152\n",
      "Epoch 312/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0200 - accuracy: 0.9946 - val_loss: 0.5171 - val_accuracy: 0.9130\n",
      "Epoch 313/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.5206 - val_accuracy: 0.9215\n",
      "Epoch 314/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0179 - accuracy: 0.9950 - val_loss: 0.5414 - val_accuracy: 0.9157\n",
      "Epoch 315/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.5680 - val_accuracy: 0.9091\n",
      "Epoch 316/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.5697 - val_accuracy: 0.9097\n",
      "Epoch 317/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.6047 - val_accuracy: 0.9080\n",
      "Epoch 318/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.5408 - val_accuracy: 0.9066\n",
      "Epoch 319/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.5317 - val_accuracy: 0.9069\n",
      "Epoch 320/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9935 - val_loss: 0.5449 - val_accuracy: 0.9086\n",
      "Epoch 321/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.5294 - val_accuracy: 0.9124\n",
      "Epoch 322/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.5484 - val_accuracy: 0.9044\n",
      "Epoch 323/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.5834 - val_accuracy: 0.9025\n",
      "Epoch 324/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.6163 - val_accuracy: 0.9075\n",
      "Epoch 325/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0192 - accuracy: 0.9948 - val_loss: 0.5901 - val_accuracy: 0.9116\n",
      "Epoch 326/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0168 - accuracy: 0.9940 - val_loss: 0.5804 - val_accuracy: 0.9080\n",
      "Epoch 327/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9935 - val_loss: 0.6200 - val_accuracy: 0.8973\n",
      "Epoch 328/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.5930 - val_accuracy: 0.9036\n",
      "Epoch 329/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.6027 - val_accuracy: 0.9031\n",
      "Epoch 330/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0185 - accuracy: 0.9934 - val_loss: 0.5526 - val_accuracy: 0.9058\n",
      "Epoch 331/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 0.9953 - val_loss: 0.5773 - val_accuracy: 0.9097\n",
      "Epoch 332/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0182 - accuracy: 0.9951 - val_loss: 0.5698 - val_accuracy: 0.9075\n",
      "Epoch 333/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 0.9955 - val_loss: 0.5574 - val_accuracy: 0.9069\n",
      "Epoch 334/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.5196 - val_accuracy: 0.9108\n",
      "Epoch 335/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.5831 - val_accuracy: 0.9077\n",
      "Epoch 336/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.5937 - val_accuracy: 0.9066\n",
      "Epoch 337/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.6170 - val_accuracy: 0.9031\n",
      "Epoch 338/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.5723 - val_accuracy: 0.9064\n",
      "Epoch 339/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.5589 - val_accuracy: 0.9097\n",
      "Epoch 340/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 0.5882 - val_accuracy: 0.9031\n",
      "Epoch 341/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.5549 - val_accuracy: 0.9088\n",
      "Epoch 342/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.5499 - val_accuracy: 0.9135\n",
      "Epoch 343/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.5647 - val_accuracy: 0.9110\n",
      "Epoch 344/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.5247 - val_accuracy: 0.9138\n",
      "Epoch 345/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.5554 - val_accuracy: 0.9152\n",
      "Epoch 346/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.5077 - val_accuracy: 0.9155\n",
      "Epoch 347/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.5319 - val_accuracy: 0.9152\n",
      "Epoch 348/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.5498 - val_accuracy: 0.9102\n",
      "Epoch 349/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0236 - accuracy: 0.9943 - val_loss: 0.5817 - val_accuracy: 0.9099\n",
      "Epoch 350/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.5487 - val_accuracy: 0.9110\n",
      "Epoch 351/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.5761 - val_accuracy: 0.9099\n",
      "Epoch 352/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.5555 - val_accuracy: 0.9064\n",
      "Epoch 353/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.5779 - val_accuracy: 0.9072\n",
      "Epoch 354/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.5847 - val_accuracy: 0.9025\n",
      "Epoch 355/600\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.5660 - val_accuracy: 0.9105\n",
      "Epoch 356/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.5387 - val_accuracy: 0.9135\n",
      "Epoch 357/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.5598 - val_accuracy: 0.9042\n",
      "Epoch 358/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.5406 - val_accuracy: 0.9099\n",
      "Epoch 359/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 0.5481 - val_accuracy: 0.9066\n",
      "Epoch 360/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.5437 - val_accuracy: 0.9091\n",
      "Epoch 361/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.5418 - val_accuracy: 0.9099\n",
      "Epoch 362/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.5485 - val_accuracy: 0.9119\n",
      "Epoch 363/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.5795 - val_accuracy: 0.9069\n",
      "Epoch 364/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0230 - accuracy: 0.9951 - val_loss: 0.5362 - val_accuracy: 0.9119\n",
      "Epoch 365/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.5322 - val_accuracy: 0.9077\n",
      "Epoch 366/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.5858 - val_accuracy: 0.9053\n",
      "Epoch 367/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 0.5695 - val_accuracy: 0.9061\n",
      "Epoch 368/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.5630 - val_accuracy: 0.9097\n",
      "Epoch 369/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.5784 - val_accuracy: 0.9080\n",
      "Epoch 370/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0215 - accuracy: 0.9935 - val_loss: 0.5794 - val_accuracy: 0.9022\n",
      "Epoch 371/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.5411 - val_accuracy: 0.9077\n",
      "Epoch 372/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 0.5705 - val_accuracy: 0.9053\n",
      "Epoch 373/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.5664 - val_accuracy: 0.9069\n",
      "Epoch 374/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.5841 - val_accuracy: 0.9135\n",
      "Epoch 375/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.5915 - val_accuracy: 0.9166\n",
      "Epoch 376/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 0.5782 - val_accuracy: 0.9083\n",
      "Epoch 377/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.5841 - val_accuracy: 0.9061\n",
      "Epoch 378/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.5649 - val_accuracy: 0.9108\n",
      "Epoch 379/600\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.5930 - val_accuracy: 0.9119\n",
      "Epoch 380/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.6151 - val_accuracy: 0.9119\n",
      "Epoch 381/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0201 - accuracy: 0.9950 - val_loss: 0.6016 - val_accuracy: 0.9028\n",
      "Epoch 382/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 0.5784 - val_accuracy: 0.9047\n",
      "Epoch 383/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0169 - accuracy: 0.9959 - val_loss: 0.6348 - val_accuracy: 0.8981\n",
      "Epoch 384/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.6083 - val_accuracy: 0.9031\n",
      "Epoch 385/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.5767 - val_accuracy: 0.9072\n",
      "Epoch 386/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.5864 - val_accuracy: 0.9088\n",
      "Epoch 387/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.5929 - val_accuracy: 0.9053\n",
      "Epoch 388/600\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 0.0229 - accuracy: 0.9940 - val_loss: 0.5968 - val_accuracy: 0.9064\n",
      "Epoch 389/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.5740 - val_accuracy: 0.9069\n",
      "Epoch 390/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.6398 - val_accuracy: 0.9000\n",
      "Epoch 391/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.5890 - val_accuracy: 0.9105\n",
      "Epoch 392/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.6193 - val_accuracy: 0.9075\n",
      "Epoch 393/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.5693 - val_accuracy: 0.9102\n",
      "Epoch 394/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.5773 - val_accuracy: 0.9042\n",
      "Epoch 395/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.5803 - val_accuracy: 0.9083\n",
      "Epoch 396/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.5841 - val_accuracy: 0.9064\n",
      "Epoch 397/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.5724 - val_accuracy: 0.9055\n",
      "Epoch 398/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0213 - accuracy: 0.9942 - val_loss: 0.5898 - val_accuracy: 0.9072\n",
      "Epoch 399/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.5803 - val_accuracy: 0.9110\n",
      "Epoch 400/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.5992 - val_accuracy: 0.9135\n",
      "Epoch 401/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.5885 - val_accuracy: 0.9127\n",
      "Epoch 402/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 0.5407 - val_accuracy: 0.9160\n",
      "Epoch 403/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.5368 - val_accuracy: 0.9099\n",
      "Epoch 404/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0182 - accuracy: 0.9950 - val_loss: 0.5478 - val_accuracy: 0.9091\n",
      "Epoch 405/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.5576 - val_accuracy: 0.9102\n",
      "Epoch 406/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.5514 - val_accuracy: 0.9121\n",
      "Epoch 407/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.6114 - val_accuracy: 0.9097\n",
      "Epoch 408/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.5820 - val_accuracy: 0.9113\n",
      "Epoch 409/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.6306 - val_accuracy: 0.9094\n",
      "Epoch 410/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.6329 - val_accuracy: 0.9094\n",
      "Epoch 411/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.6105 - val_accuracy: 0.9080\n",
      "Epoch 412/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.5928 - val_accuracy: 0.9121\n",
      "Epoch 413/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0129 - accuracy: 0.9948 - val_loss: 0.5806 - val_accuracy: 0.9149\n",
      "Epoch 414/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.6246 - val_accuracy: 0.9102\n",
      "Epoch 415/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.6030 - val_accuracy: 0.9116\n",
      "Epoch 416/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.5892 - val_accuracy: 0.9130\n",
      "Epoch 417/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0298 - accuracy: 0.9919 - val_loss: 0.5402 - val_accuracy: 0.9121\n",
      "Epoch 418/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0305 - accuracy: 0.9925 - val_loss: 0.4639 - val_accuracy: 0.9135\n",
      "Epoch 419/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.5077 - val_accuracy: 0.9174\n",
      "Epoch 420/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.5083 - val_accuracy: 0.9141\n",
      "Epoch 421/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.5779 - val_accuracy: 0.9130\n",
      "Epoch 422/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.5869 - val_accuracy: 0.9143\n",
      "Epoch 423/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.5768 - val_accuracy: 0.9121\n",
      "Epoch 424/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 0.5719 - val_accuracy: 0.9132\n",
      "Epoch 425/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.5623 - val_accuracy: 0.9157\n",
      "Epoch 426/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.5999 - val_accuracy: 0.9182\n",
      "Epoch 427/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 0.6317 - val_accuracy: 0.9138\n",
      "Epoch 428/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.5678 - val_accuracy: 0.9141\n",
      "Epoch 429/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.6271 - val_accuracy: 0.9097\n",
      "Epoch 430/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.6658 - val_accuracy: 0.9058\n",
      "Epoch 431/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.6499 - val_accuracy: 0.9108\n",
      "Epoch 432/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0227 - accuracy: 0.9946 - val_loss: 0.6659 - val_accuracy: 0.9028\n",
      "Epoch 433/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.6215 - val_accuracy: 0.9042\n",
      "Epoch 434/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.5701 - val_accuracy: 0.9094\n",
      "Epoch 435/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.5682 - val_accuracy: 0.9116\n",
      "Epoch 436/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.5961 - val_accuracy: 0.9102\n",
      "Epoch 437/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0260 - accuracy: 0.9940 - val_loss: 0.5236 - val_accuracy: 0.9094\n",
      "Epoch 438/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.5229 - val_accuracy: 0.9132\n",
      "Epoch 439/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.5358 - val_accuracy: 0.9160\n",
      "Epoch 440/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.5803 - val_accuracy: 0.9141\n",
      "Epoch 441/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0142 - accuracy: 0.9962 - val_loss: 0.5524 - val_accuracy: 0.9166\n",
      "Epoch 442/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.5476 - val_accuracy: 0.9185\n",
      "Epoch 443/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.5567 - val_accuracy: 0.9124\n",
      "Epoch 444/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.5623 - val_accuracy: 0.9138\n",
      "Epoch 445/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0138 - accuracy: 0.9950 - val_loss: 0.5480 - val_accuracy: 0.9080\n",
      "Epoch 446/600\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.5141 - val_accuracy: 0.9157\n",
      "Epoch 447/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 14ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.5451 - val_accuracy: 0.9132\n",
      "Epoch 448/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.5680 - val_accuracy: 0.9119\n",
      "Epoch 449/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.5768 - val_accuracy: 0.9116\n",
      "Epoch 450/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.5859 - val_accuracy: 0.9141\n",
      "Epoch 451/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.5790 - val_accuracy: 0.9119\n",
      "Epoch 452/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0236 - accuracy: 0.9943 - val_loss: 0.5850 - val_accuracy: 0.9072\n",
      "Epoch 453/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.5587 - val_accuracy: 0.9127\n",
      "Epoch 454/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.5595 - val_accuracy: 0.9119\n",
      "Epoch 455/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.5381 - val_accuracy: 0.9094\n",
      "Epoch 456/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.5411 - val_accuracy: 0.9138\n",
      "Epoch 457/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.5555 - val_accuracy: 0.9121\n",
      "Epoch 458/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.5683 - val_accuracy: 0.9077\n",
      "Epoch 459/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.5795 - val_accuracy: 0.9135\n",
      "Epoch 460/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.5466 - val_accuracy: 0.9130\n",
      "Epoch 461/600\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.5746 - val_accuracy: 0.9102\n",
      "Epoch 462/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.6286 - val_accuracy: 0.9097\n",
      "Epoch 463/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.5610 - val_accuracy: 0.9116\n",
      "Epoch 464/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.5524 - val_accuracy: 0.9146\n",
      "Epoch 465/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.5697 - val_accuracy: 0.9143\n",
      "Epoch 466/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.5897 - val_accuracy: 0.9141\n",
      "Epoch 467/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.5817 - val_accuracy: 0.9149\n",
      "Epoch 468/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 0.5753 - val_accuracy: 0.9168\n",
      "Epoch 469/600\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.5647 - val_accuracy: 0.9149\n",
      "Epoch 470/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 0.5591 - val_accuracy: 0.9171\n",
      "Epoch 471/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0154 - accuracy: 0.9970 - val_loss: 0.6040 - val_accuracy: 0.9108\n",
      "Epoch 472/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.5357 - val_accuracy: 0.9108\n",
      "Epoch 473/600\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.5610 - val_accuracy: 0.9121\n",
      "Epoch 474/600\n",
      "58/58 [==============================] - 1s 13ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.5646 - val_accuracy: 0.9094\n",
      "Epoch 475/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.5850 - val_accuracy: 0.9108\n",
      "Epoch 476/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.5854 - val_accuracy: 0.9113\n",
      "Epoch 477/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.6265 - val_accuracy: 0.9066\n",
      "Epoch 478/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.6339 - val_accuracy: 0.9132\n",
      "Epoch 479/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.6129 - val_accuracy: 0.9152\n",
      "Epoch 480/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.6376 - val_accuracy: 0.9135\n",
      "Epoch 481/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0193 - accuracy: 0.9959 - val_loss: 0.6582 - val_accuracy: 0.9094\n",
      "Epoch 482/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.5779 - val_accuracy: 0.9130\n",
      "Epoch 483/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.5908 - val_accuracy: 0.9149\n",
      "Epoch 484/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.5645 - val_accuracy: 0.9138\n",
      "Epoch 485/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9934 - val_loss: 0.5660 - val_accuracy: 0.9132\n",
      "Epoch 486/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.5665 - val_accuracy: 0.9121\n",
      "Epoch 487/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.6001 - val_accuracy: 0.9138\n",
      "Epoch 488/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.6048 - val_accuracy: 0.9099\n",
      "Epoch 489/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.5817 - val_accuracy: 0.9146\n",
      "Epoch 490/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.6432 - val_accuracy: 0.9116\n",
      "Epoch 491/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.5888 - val_accuracy: 0.9160\n",
      "Epoch 492/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.6010 - val_accuracy: 0.9163\n",
      "Epoch 493/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.5841 - val_accuracy: 0.9157\n",
      "Epoch 494/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0088 - accuracy: 0.9962 - val_loss: 0.5827 - val_accuracy: 0.9152\n",
      "Epoch 495/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.6289 - val_accuracy: 0.9124\n",
      "Epoch 496/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.6658 - val_accuracy: 0.9110\n",
      "Epoch 497/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.6524 - val_accuracy: 0.9121\n",
      "Epoch 498/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0198 - accuracy: 0.9951 - val_loss: 0.6386 - val_accuracy: 0.9097\n",
      "Epoch 499/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.5748 - val_accuracy: 0.9179\n",
      "Epoch 500/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.6349 - val_accuracy: 0.9143\n",
      "Epoch 501/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.5980 - val_accuracy: 0.9143\n",
      "Epoch 502/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0159 - accuracy: 0.9961 - val_loss: 0.6362 - val_accuracy: 0.9152\n",
      "Epoch 503/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.6087 - val_accuracy: 0.9174\n",
      "Epoch 504/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.6333 - val_accuracy: 0.9163\n",
      "Epoch 505/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0094 - accuracy: 0.9962 - val_loss: 0.6351 - val_accuracy: 0.9182\n",
      "Epoch 506/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.6422 - val_accuracy: 0.9160\n",
      "Epoch 507/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0184 - accuracy: 0.9954 - val_loss: 0.6642 - val_accuracy: 0.9119\n",
      "Epoch 508/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.6466 - val_accuracy: 0.9138\n",
      "Epoch 509/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 0.5612 - val_accuracy: 0.9143\n",
      "Epoch 510/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.5966 - val_accuracy: 0.9152\n",
      "Epoch 511/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.5799 - val_accuracy: 0.9196\n",
      "Epoch 512/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.6009 - val_accuracy: 0.9160\n",
      "Epoch 513/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.6217 - val_accuracy: 0.9163\n",
      "Epoch 514/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9961 - val_loss: 0.6248 - val_accuracy: 0.9146\n",
      "Epoch 515/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.5872 - val_accuracy: 0.9143\n",
      "Epoch 516/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.5867 - val_accuracy: 0.9146\n",
      "Epoch 517/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0089 - accuracy: 0.9967 - val_loss: 0.6141 - val_accuracy: 0.9182\n",
      "Epoch 518/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.5998 - val_accuracy: 0.9174\n",
      "Epoch 519/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.6208 - val_accuracy: 0.9168\n",
      "Epoch 520/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.6694 - val_accuracy: 0.9152\n",
      "Epoch 521/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.5911 - val_accuracy: 0.9152\n",
      "Epoch 522/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.6345 - val_accuracy: 0.9094\n",
      "Epoch 523/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 0.6071 - val_accuracy: 0.9146\n",
      "Epoch 524/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.6035 - val_accuracy: 0.9157\n",
      "Epoch 525/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.6187 - val_accuracy: 0.9141\n",
      "Epoch 526/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.6510 - val_accuracy: 0.9127\n",
      "Epoch 527/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.6022 - val_accuracy: 0.9157\n",
      "Epoch 528/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.5946 - val_accuracy: 0.9171\n",
      "Epoch 529/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.6325 - val_accuracy: 0.9138\n",
      "Epoch 530/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0250 - accuracy: 0.9939 - val_loss: 0.6276 - val_accuracy: 0.9119\n",
      "Epoch 531/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0182 - accuracy: 0.9955 - val_loss: 0.6133 - val_accuracy: 0.9179\n",
      "Epoch 532/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.6408 - val_accuracy: 0.9174\n",
      "Epoch 533/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.6591 - val_accuracy: 0.9121\n",
      "Epoch 534/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.6226 - val_accuracy: 0.9127\n",
      "Epoch 535/600\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.6286 - val_accuracy: 0.9171\n",
      "Epoch 536/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.6347 - val_accuracy: 0.9152\n",
      "Epoch 537/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.5937 - val_accuracy: 0.9149\n",
      "Epoch 538/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.6293 - val_accuracy: 0.9155\n",
      "Epoch 539/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.6267 - val_accuracy: 0.9143\n",
      "Epoch 540/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.6314 - val_accuracy: 0.9135\n",
      "Epoch 541/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.6360 - val_accuracy: 0.9091\n",
      "Epoch 542/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.6440 - val_accuracy: 0.9102\n",
      "Epoch 543/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.6423 - val_accuracy: 0.9149\n",
      "Epoch 544/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.6039 - val_accuracy: 0.9177\n",
      "Epoch 545/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0224 - accuracy: 0.9947 - val_loss: 0.6401 - val_accuracy: 0.9130\n",
      "Epoch 546/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.6237 - val_accuracy: 0.9152\n",
      "Epoch 547/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.6205 - val_accuracy: 0.9149\n",
      "Epoch 548/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.6092 - val_accuracy: 0.9171\n",
      "Epoch 549/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.5827 - val_accuracy: 0.9188\n",
      "Epoch 550/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.5977 - val_accuracy: 0.9152\n",
      "Epoch 551/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.5867 - val_accuracy: 0.9155\n",
      "Epoch 552/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.5907 - val_accuracy: 0.9171\n",
      "Epoch 553/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.6260 - val_accuracy: 0.9143\n",
      "Epoch 554/600\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.6249 - val_accuracy: 0.9177\n",
      "Epoch 555/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.5880 - val_accuracy: 0.9157\n",
      "Epoch 556/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.5996 - val_accuracy: 0.9177\n",
      "Epoch 557/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.6251 - val_accuracy: 0.9146\n",
      "Epoch 558/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.6386 - val_accuracy: 0.9102\n",
      "Epoch 559/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.5831 - val_accuracy: 0.9199\n",
      "Epoch 560/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.5976 - val_accuracy: 0.9132\n",
      "Epoch 561/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0143 - accuracy: 0.9962 - val_loss: 0.6239 - val_accuracy: 0.9130\n",
      "Epoch 562/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.6172 - val_accuracy: 0.9135\n",
      "Epoch 563/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.6215 - val_accuracy: 0.9113\n",
      "Epoch 564/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.6267 - val_accuracy: 0.9130\n",
      "Epoch 565/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.6378 - val_accuracy: 0.9113\n",
      "Epoch 566/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.6547 - val_accuracy: 0.9124\n",
      "Epoch 567/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.5838 - val_accuracy: 0.9149\n",
      "Epoch 568/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0111 - accuracy: 0.9954 - val_loss: 0.5924 - val_accuracy: 0.9190\n",
      "Epoch 569/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0099 - accuracy: 0.9962 - val_loss: 0.6193 - val_accuracy: 0.9166\n",
      "Epoch 570/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 0.6742 - val_accuracy: 0.9124\n",
      "Epoch 571/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0107 - accuracy: 0.9957 - val_loss: 0.6698 - val_accuracy: 0.9138\n",
      "Epoch 572/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.6680 - val_accuracy: 0.9091\n",
      "Epoch 573/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.6580 - val_accuracy: 0.9130\n",
      "Epoch 574/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.6731 - val_accuracy: 0.9127\n",
      "Epoch 575/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 0.6195 - val_accuracy: 0.9138\n",
      "Epoch 576/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.6101 - val_accuracy: 0.9135\n",
      "Epoch 577/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.5877 - val_accuracy: 0.9179\n",
      "Epoch 578/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.6412 - val_accuracy: 0.9132\n",
      "Epoch 579/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.6388 - val_accuracy: 0.9163\n",
      "Epoch 580/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.6766 - val_accuracy: 0.9066\n",
      "Epoch 581/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.6239 - val_accuracy: 0.9127\n",
      "Epoch 582/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.5974 - val_accuracy: 0.9127\n",
      "Epoch 583/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0204 - accuracy: 0.9947 - val_loss: 0.5502 - val_accuracy: 0.9168\n",
      "Epoch 584/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0221 - accuracy: 0.9946 - val_loss: 0.5950 - val_accuracy: 0.9135\n",
      "Epoch 585/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.6042 - val_accuracy: 0.9124\n",
      "Epoch 586/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.5850 - val_accuracy: 0.9132\n",
      "Epoch 587/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.5904 - val_accuracy: 0.9152\n",
      "Epoch 588/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.6437 - val_accuracy: 0.9146\n",
      "Epoch 589/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.6303 - val_accuracy: 0.9138\n",
      "Epoch 590/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.6682 - val_accuracy: 0.9110\n",
      "Epoch 591/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.6437 - val_accuracy: 0.9102\n",
      "Epoch 592/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.6473 - val_accuracy: 0.9143\n",
      "Epoch 593/600\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.6512 - val_accuracy: 0.9121\n",
      "Epoch 594/600\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.6272 - val_accuracy: 0.9146\n",
      "Epoch 595/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.6219 - val_accuracy: 0.9155\n",
      "Epoch 596/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.6328 - val_accuracy: 0.9188\n",
      "Epoch 597/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.7345 - val_accuracy: 0.9108\n",
      "Epoch 598/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.6606 - val_accuracy: 0.9130\n",
      "Epoch 599/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.6569 - val_accuracy: 0.9155\n",
      "Epoch 600/600\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.6415 - val_accuracy: 0.9121\n"
     ]
    }
   ],
   "source": [
    "model = k.models.Sequential([\n",
    "    k.layers.Dense(512, activation='relu', input_shape=(X_train_3.shape[1],)),\n",
    "    k.layers.Dropout(0.2),\n",
    "    \n",
    "    k.layers.Dense(256, activation='relu'),\n",
    "    k.layers.Dropout(0.2),\n",
    "    \n",
    "    k.layers.Dense(128, activation='relu'),\n",
    "    k.layers.Dropout(0.2),\n",
    "    \n",
    "    k.layers.Dense(64, activation='relu'),\n",
    "    k.layers.Dropout(0.2),\n",
    "    \n",
    "    k.layers.Dense(10, activation='softmax')  \n",
    "])\n",
    "print(model.summary())\n",
    "model_history = train_model(model=model, epochs=600, optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd8ccf",
   "metadata": {},
   "source": [
    "## 4. Quantitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "944a1554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Here : Plot loss function and accuracy\n",
    "plt.title('Loss')\n",
    "plt.plot(model_history.history['loss'], 'r')\n",
    "plt.plot(model_history.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b48c4c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(model_history.history['accuracy'], 'r')\n",
    "plt.plot(model_history.history['val_accuracy'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e593eee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Data/models/model3\\assets\n"
     ]
    }
   ],
   "source": [
    "#Save model\n",
    "model.save('Data/models/model3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144e15d",
   "metadata": {},
   "source": [
    "## 5. Qualitative analysis (per model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77ecb36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the accuracy of a model on batch of size testing_batch_size\n",
    "def test_batch_accuracy(model, X_test_set, y_test_set, testing_batch_size=16):\n",
    "    ind = random.randint(1, X_test_set.shape[0] - testing_batch_size + 1)\n",
    "\n",
    "    outputs = model(X_test_set[ind:ind+testing_batch_size])\n",
    "    groundtruth = y_test_set[ind:ind+testing_batch_size]\n",
    "\n",
    "    predicted_labels = []\n",
    "    for i in range(len(outputs)):\n",
    "        max_value = 0\n",
    "        for j in range(len(outputs[0])):\n",
    "            if outputs[i][j] > max_value:\n",
    "                max_value = outputs[i][j]\n",
    "                index = j\n",
    "        predicted_labels.append(index)\n",
    "\n",
    "    print(\"Groundtruth : \", groundtruth)\n",
    "    print(\"Predicted labels : \", predicted_labels) \n",
    "\n",
    "    classes = ('blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock')\n",
    "\n",
    "    print('GroundTruth: ', ' '.join(f'{classes[groundtruth[j]]:5s}' for j in range(testing_batch_size)))\n",
    "    print('Predicted: ', ' '.join(f'{classes[predicted_labels[j]]:5s}'\n",
    "                                  for j in range(testing_batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d1419e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54b2ea6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on an old data batch\n",
      "Groundtruth :  [5 4 6 9 9 2 7 3 2 0 7 9 2 7 6 2]\n",
      "Predicted labels :  [1, 4, 6, 9, 9, 2, 7, 3, 2, 0, 7, 9, 2, 7, 6, 2]\n",
      "GroundTruth:  jazz  hiphop metal rock  rock  country pop   disco country blues pop   rock  country pop   metal country\n",
      "Predicted:  classical hiphop metal rock  rock  country pop   disco country blues pop   rock  country pop   metal country\n",
      "Prediction on a new data batch\n",
      "Groundtruth :  [8 5 3 6 3 2 9 9 5 5 6 2 3 0 7 6]\n",
      "Predicted labels :  [8, 5, 4, 3, 2, 2, 7, 7, 2, 2, 6, 2, 4, 7, 4, 6]\n",
      "GroundTruth:  reggae jazz  disco metal disco country rock  rock  jazz  jazz  metal country disco blues pop   metal\n",
      "Predicted:  reggae jazz  hiphop disco country country pop   pop   country country metal country hiphop pop   hiphop metal\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of model1\n",
    "model1 = keras.models.load_model('Data/models/model1')\n",
    "print(\"Prediction on an old data batch\")\n",
    "test_batch_accuracy(model1, X_test, y_test)\n",
    "print(\"Prediction on a new data batch\")\n",
    "test_batch_accuracy(model1, X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c6707bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on an old data batch\n",
      "Groundtruth :  [5 3 9 0 5 6 8 4 4 2 8 3 4 6 6 8]\n",
      "Predicted labels :  [5, 3, 9, 0, 5, 6, 8, 4, 4, 2, 8, 3, 4, 6, 6, 8]\n",
      "GroundTruth:  jazz  disco rock  blues jazz  metal reggae hiphop hiphop country reggae disco hiphop metal metal reggae\n",
      "Predicted:  jazz  disco rock  blues jazz  metal reggae hiphop hiphop country reggae disco hiphop metal metal reggae\n",
      "Prediction on a new data batch\n",
      "Groundtruth :  [7 3 7 7 1 5 5 8 7 2 5 2 9 4 3 1]\n",
      "Predicted labels :  [4, 3, 7, 4, 1, 3, 2, 7, 4, 2, 1, 5, 3, 8, 4, 5]\n",
      "GroundTruth:  pop   disco pop   pop   classical jazz  jazz  reggae pop   country jazz  country rock  hiphop disco classical\n",
      "Predicted:  hiphop disco pop   hiphop classical disco country pop   hiphop country classical jazz  disco reggae hiphop jazz \n"
     ]
    }
   ],
   "source": [
    "#Accuracy of model2\n",
    "model2 = keras.models.load_model('Data/models/model2')\n",
    "print(\"Prediction on an old data batch\")\n",
    "test_batch_accuracy(model2, X_test, y_test)\n",
    "print(\"Prediction on a new data batch\")\n",
    "test_batch_accuracy(model2, X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "12c7177e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on an old data batch\n",
      "Groundtruth :  [7 4 3 3 3 8 1 8 7 2 3 8 1 9 4 1]\n",
      "Predicted labels :  [7, 4, 3, 3, 3, 8, 1, 8, 7, 2, 3, 8, 1, 9, 4, 1]\n",
      "GroundTruth:  pop   hiphop disco disco disco reggae classical reggae pop   country disco reggae classical rock  hiphop classical\n",
      "Predicted:  pop   hiphop disco disco disco reggae classical reggae pop   country disco reggae classical rock  hiphop classical\n",
      "Prediction on a new data batch\n",
      "Groundtruth :  [0 2 7 1 8 6 7 3 2 3 8 0 8 4 5 9]\n",
      "Predicted labels :  [0, 2, 7, 1, 8, 6, 7, 3, 2, 3, 8, 0, 8, 1, 5, 9]\n",
      "GroundTruth:  blues country pop   classical reggae metal pop   disco country disco reggae blues reggae hiphop jazz  rock \n",
      "Predicted:  blues country pop   classical reggae metal pop   disco country disco reggae blues reggae classical jazz  rock \n"
     ]
    }
   ],
   "source": [
    "#Accuracy of model3\n",
    "model3 = keras.models.load_model('Data/models/model3')\n",
    "print(\"Prediction on an old data batch\")\n",
    "test_batch_accuracy(model3, X_test, y_test)\n",
    "print(\"Prediction on a new data batch\")\n",
    "test_batch_accuracy(model3, X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b79ac4",
   "metadata": {},
   "source": [
    "## 6. Data expansion script (add new songs to the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eae889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the download file as a 30 second wav file in the given path\n",
    "def save_30_seconds(download_path, music_name, save_path, i):\n",
    "    song, sr = librosa.load(download_path)\n",
    "\n",
    "    #Cut the song to a 30 second sample\n",
    "    #400000 + 22050*30 = 1061500 \n",
    "    song = song[400000:1061500]\n",
    "\n",
    "    #Save it in the appropriate folder\n",
    "    scipy.io.wavfile.write(os.path.join(save_path,music_name), sr, song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94084295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a 3 seconds song mini-sample (3 seconds are selected based on index)\n",
    "def get_3_seconds(song, index):\n",
    "    song_minisample = song[index*66149:(index+1)*66149]\n",
    "    return song_minisample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05ec6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and returns a list containing all the selected features of a song.\n",
    "def compute_features(song, song_name, song_label, index):\n",
    "    filename = song_name+'.'+str(index)+'.wav'\n",
    "    length = 66149\n",
    "    chroma_stft_mean = np.mean(librosa.feature.chroma_stft(song))\n",
    "    chroma_stft_var = np.var(librosa.feature.chroma_stft(song))\n",
    "    rms_mean = np.mean(librosa.feature.rms(song))\n",
    "    rms_var = np.var(librosa.feature.rms(song))\n",
    "    spectral_centroid_mean = np.mean(librosa.feature.spectral_centroid(song))\n",
    "    spectral_centroid_var = np.var(librosa.feature.spectral_centroid(song))\n",
    "    spectral_bandwidth_mean = np.mean(librosa.feature.spectral_bandwidth(song))\n",
    "    spectral_bandwidth_var = np.var(librosa.feature.spectral_bandwidth(song))\n",
    "    rolloff_mean = np.mean(librosa.feature.spectral_rolloff(song))\n",
    "    rolloff_var = np.var(librosa.feature.spectral_rolloff(song))\n",
    "    zero_crossing_rate_mean = np.mean(librosa.feature.zero_crossing_rate(song))\n",
    "    zero_crossing_rate_var = np.var(librosa.feature.zero_crossing_rate(song))\n",
    "    y_harm, y_perc = librosa.effects.hpss(song)\n",
    "    harmony_mean = np.mean(y_harm) \n",
    "    harmony_var = np.var(y_harm)\n",
    "    perceptr_mean = np.mean(y_perc)\n",
    "    perceptr_var = np.var(y_perc)\n",
    "    tempo, _ = librosa.beat.beat_track(song, sr=22050)\n",
    "    # 20 fois les 2\n",
    "    mfcc = librosa.feature.mfcc(song)\n",
    "    mfcc_mean_list = []\n",
    "    mfcc_var_list = []\n",
    "    for i in range(20):\n",
    "        mfcc_mean = np.mean(mfcc[i])\n",
    "        mfcc_var = np.var(mfcc[i])\n",
    "        mfcc_mean_list.append(mfcc_mean)\n",
    "        mfcc_var_list.append(mfcc_var)\n",
    "    label = song_label\n",
    "    csv_line = list((filename, length, chroma_stft_mean, chroma_stft_var, rms_mean, rms_var, spectral_centroid_mean, spectral_centroid_var, spectral_bandwidth_mean, spectral_bandwidth_var, rolloff_mean, rolloff_var, zero_crossing_rate_mean, zero_crossing_rate_var, harmony_mean, harmony_var, perceptr_mean, perceptr_var, tempo))\n",
    "    for i in range(20):\n",
    "        csv_line.append(mfcc_mean_list[i])\n",
    "        csv_line.append(mfcc_var_list[i])\n",
    "    csv_line.append(label)\n",
    "    return csv_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e20b1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add an entry to the csv features file.\n",
    "def add_line_to_csv(entry):\n",
    "    csv_path = 'Data/features_3_sec.csv'\n",
    "    with open(csv_path, 'a', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # write the entry\n",
    "        writer.writerow(entry)\n",
    "\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "659329fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the 10 sets of computed features of a 30-second song to the csv features file\n",
    "def add_features_to_csv(song, song_name, label):\n",
    "    #Loop to get 3 seconds and for each 3 seconds compute features\n",
    "    #At the end of each loop, build a line of the csv file\n",
    "    for i in range(10):\n",
    "        three_sec = get_3_seconds(song, i)\n",
    "        csv_line = compute_features(three_sec, song_name, label, i)\n",
    "        add_line_to_csv(csv_line)\n",
    "    print(\"Successfully added song features to data csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32d4de4",
   "metadata": {},
   "source": [
    "### Add songs to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56282fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.io.wavfile import write\n",
    "import statistics\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "199ca6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a song to the dataset.\n",
    "def add_song(path, name, i):\n",
    "    music_name = name\n",
    "    download_path = path+music_name\n",
    "\n",
    "    music_no_wav = music_name.split(\".\")\n",
    "    music_no_wav = music_no_wav[0]\n",
    "\n",
    "    #Here : change i to have the good index in classes\n",
    "    classes = ('blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock')\n",
    "    music_class = classes[i]\n",
    "\n",
    "    save_path = 'Data/genres_original/'+music_class\n",
    "\n",
    "    print(\"Downloaded file\", music_name, \"at : \" ,download_path)\n",
    "    print(\"Saved 30 sec sample at : \" , save_path)\n",
    "\n",
    "    save_30_seconds(download_path, music_name, save_path, i)\n",
    "\n",
    "    song, sr = librosa.load(save_path+'/'+music_name)\n",
    "\n",
    "    add_features_to_csv(song, music_no_wav, music_class)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "517c71fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded file AC_DC - Shot In The Dark (Official Audio).wav at :  Data/recents/rock/AC_DC - Shot In The Dark (Official Audio).wav\n",
      "Saved 30 sec sample at :  Data/genres_original/rock\n",
      "Successfully added song features to data csv\n",
      "Song added\n",
      "Downloaded file Anthony Green - 'Don't Dance' (Official Video).wav at :  Data/recents/rock/Anthony Green - 'Don't Dance' (Official Video).wav\n",
      "Saved 30 sec sample at :  Data/genres_original/rock\n",
      "Successfully added song features to data csv\n",
      "Song added\n",
      "Downloaded file Cult to Follow Leave It All Behind You Lyrics.wav at :  Data/recents/rock/Cult to Follow Leave It All Behind You Lyrics.wav\n",
      "Saved 30 sec sample at :  Data/genres_original/rock\n",
      "Successfully added song features to data csv\n",
      "Song added\n",
      "Downloaded file Royal Blood - Trouble's Coming (Official Audio).wav at :  Data/recents/rock/Royal Blood - Trouble's Coming (Official Audio).wav\n",
      "Saved 30 sec sample at :  Data/genres_original/rock\n",
      "Successfully added song features to data csv\n",
      "Song added\n",
      "Downloaded file Suber Oaks - Fallin' (Official Audio).wav at :  Data/recents/rock/Suber Oaks - Fallin' (Official Audio).wav\n",
      "Saved 30 sec sample at :  Data/genres_original/rock\n",
      "Successfully added song features to data csv\n",
      "Song added\n",
      "Downloaded file Tally Hall - Welcome To Tally Hall.wav at :  Data/recents/rock/Tally Hall - Welcome To Tally Hall.wav\n",
      "Saved 30 sec sample at :  Data/genres_original/rock\n",
      "Successfully added song features to data csv\n",
      "Song added\n",
      "Downloaded file The Black Keys - Lonely Boy [Official Music Video].wav at :  Data/recents/rock/The Black Keys - Lonely Boy [Official Music Video].wav\n",
      "Saved 30 sec sample at :  Data/genres_original/rock\n",
      "Successfully added song features to data csv\n",
      "Song added\n"
     ]
    }
   ],
   "source": [
    "#Loop through all the files of a genre folder and add them to the dataset\n",
    "path = 'Data/recents/rock/'\n",
    "\n",
    "#the value of i depends on which genre folder we are looping on\n",
    "#(0: 'blues', 1: 'classical', 2: 'country', 3: 'disco', 4: 'hiphop', 5: 'jazz', 6: 'metal', 7: 'pop', 8: 'reggae', 9: 'rock')\n",
    "i = 9\n",
    "\n",
    "for fn in os.listdir(path):\n",
    "    add_song(path, fn, i)\n",
    "    print(\"Song added\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RLnew)",
   "language": "python",
   "name": "rlnew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
